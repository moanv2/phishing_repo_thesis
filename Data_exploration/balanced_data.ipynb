{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T06:51:44.910953Z",
     "start_time": "2025-04-04T06:51:40.083359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"zefang-liu/phishing-email-dataset\")\n",
    "\n",
    "df = data['train'].to_pandas()\n",
    "\n",
    "print(df.head())\n",
    "print(df.info)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ],
   "id": "24a030dc9af6033f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                         Email Text  \\\n",
      "0           0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
      "1           1  the other side of * galicismos * * galicismo *...   \n",
      "2           2  re : equistar deal tickets are you still avail...   \n",
      "3           3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
      "4           4  software at incredibly low prices ( 86 % lower...   \n",
      "\n",
      "       Email Type  \n",
      "0      Safe Email  \n",
      "1      Safe Email  \n",
      "2      Safe Email  \n",
      "3  Phishing Email  \n",
      "4  Phishing Email  \n",
      "<bound method DataFrame.info of        Unnamed: 0                                         Email Text  \\\n",
      "0               0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
      "1               1  the other side of * galicismos * * galicismo *...   \n",
      "2               2  re : equistar deal tickets are you still avail...   \n",
      "3               3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
      "4               4  software at incredibly low prices ( 86 % lower...   \n",
      "...           ...                                                ...   \n",
      "18645       18646  date a lonely housewife always wanted to date ...   \n",
      "18646       18647  request submitted : access request for anita ....   \n",
      "18647       18648  re : important - prc mtg hi dorn & john , as y...   \n",
      "18648       18649  press clippings - letter on californian utilit...   \n",
      "18649       18650                                              empty   \n",
      "\n",
      "           Email Type  \n",
      "0          Safe Email  \n",
      "1          Safe Email  \n",
      "2          Safe Email  \n",
      "3      Phishing Email  \n",
      "4      Phishing Email  \n",
      "...               ...  \n",
      "18645  Phishing Email  \n",
      "18646      Safe Email  \n",
      "18647      Safe Email  \n",
      "18648      Safe Email  \n",
      "18649  Phishing Email  \n",
      "\n",
      "[18650 rows x 3 columns]>\n",
      "(18650, 3)\n",
      "Index(['Unnamed: 0', 'Email Text', 'Email Type'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-04T06:51:47.882637Z",
     "start_time": "2025-04-04T06:51:47.867733Z"
    }
   },
   "source": [
    "# Cell 1: Load and prepare your original dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming your dataset is already loaded as 'df'\n",
    "# with columns 'Email Text' and 'Email Type'\n",
    "print(\"Original dataset distribution:\")\n",
    "print(df['Email Type'].value_counts())\n",
    "\n",
    "# Convert labels to numerical format for deep learning\n",
    "label_map = {'Safe Email': 0, 'Phishing Email': 1}\n",
    "df_dl = df.copy()\n",
    "df_dl['label'] = df_dl['Email Type'].map(label_map)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset distribution:\n",
      "Email Type\n",
      "Safe Email        11322\n",
      "Phishing Email     7328\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T07:00:16.244272Z",
     "start_time": "2025-04-04T07:00:16.235010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Use your project directory explicitly\n",
    "project_dir = r'D:\\phishing_repo_thesis'  # r prefix for raw string to handle backslashes\n",
    "balanced_dir = os.path.join(project_dir, 'balanced_data_files')\n",
    "os.makedirs(balanced_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Directory created at: {balanced_dir}\")\n"
   ],
   "id": "d957da6507837327",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created at: D:\\phishing_repo_thesis\\balanced_data_files\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T07:01:03.842847Z",
     "start_time": "2025-04-04T07:01:02.675359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Create dataframe for deep learning\n",
    "# For deep learning, we'll use class weights instead of resampling\n",
    "# But we'll create train/val/test splits with stratification\n",
    "\n",
    "# Create stratified splits for deep learning\n",
    "# 70% train, 15% validation, 15% test\n",
    "X = df_dl['Email Text']\n",
    "y = df_dl['label']\n",
    "\n",
    "# First split: 85% train+val, 15% test\n",
    "X_temp, X_test_dl, y_temp, y_test_dl = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 70% train, 15% validation (from the remaining 85%)\n",
    "X_train_dl, X_val_dl, y_train_dl, y_val_dl = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.15/0.85, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Create final dataframes\n",
    "df_train_dl = pd.DataFrame({'Email Text': X_train_dl, 'label': y_train_dl}).reset_index(drop=True)\n",
    "df_val_dl = pd.DataFrame({'Email Text': X_val_dl, 'label': y_val_dl}).reset_index(drop=True)\n",
    "df_test_dl = pd.DataFrame({'Email Text': X_test_dl, 'label': y_test_dl}).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nDeep Learning datasets created:\")\n",
    "print(f\"Training set: {len(df_train_dl)} samples\")\n",
    "print(f\"Validation set: {len(df_val_dl)} samples\")\n",
    "print(f\"Test set: {len(df_test_dl)} samples\")\n",
    "print(\"Class distribution in training set:\")\n",
    "print(df_train_dl['label'].value_counts())\n",
    "\n",
    "# Calculate class weights for deep learning\n",
    "total_samples = len(df_train_dl)\n",
    "n_classes = 2\n",
    "class_counts = df_train_dl['label'].value_counts().sort_index()\n",
    "class_weights = total_samples / (n_classes * class_counts)\n",
    "print(\"\\nClass weights for deep learning:\")\n",
    "print(class_weights.to_dict())\n",
    "\n",
    "# Save deep learning datasets\n",
    "# Save your files with absolute paths\n",
    "df_train_dl.to_csv(os.path.join(balanced_dir, 'train_dl.csv'), index=False)\n",
    "df_val_dl.to_csv(os.path.join(balanced_dir, 'val_dl.csv'), index=False)\n",
    "df_test_dl.to_csv(os.path.join(balanced_dir, 'test_dl.csv'), index=False)\n",
    "\n",
    "# Print the location so you know where to look\n",
    "print(f\"Files saved to: {balanced_dir}\")"
   ],
   "id": "4973e9de6fd16e04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep Learning datasets created:\n",
      "Training set: 13054 samples\n",
      "Validation set: 2798 samples\n",
      "Test set: 2798 samples\n",
      "Class distribution in training set:\n",
      "label\n",
      "0    7924\n",
      "1    5130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class weights for deep learning:\n",
      "{0: 0.8237001514386674, 1: 1.2723196881091619}\n",
      "Files saved to: D:\\phishing_repo_thesis\\balanced_data_files\n",
      "Files saved to: D:\\phishing_repo_thesis\\balanced_data_files\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T07:14:13.462435Z",
     "start_time": "2025-04-04T07:13:05.367759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Create dataframe for traditional ML\n",
    "# For traditional ML, we'll use simple random oversampling instead of SMOTE\n",
    "\n",
    "# First, ensure all text values are strings, not None\n",
    "df['Email Text'] = df['Email Text'].fillna(\"\").astype(str)\n",
    "\n",
    "# Extract features using TF-IDF (common for traditional ML)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df['Email Text'])\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "feature_names = [f'feature_{i}' for i in range(X_tfidf.shape[1])]\n",
    "X_df = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "X_df['Email Type'] = df['Email Type']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
    "    X_df.drop('Email Type', axis=1),\n",
    "    X_df['Email Type'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X_df['Email Type']\n",
    ")\n",
    "\n",
    "# Get counts by class\n",
    "train_class_counts = y_train_ml.value_counts()\n",
    "majority_count = train_class_counts.max()\n",
    "majority_class = train_class_counts.idxmax()\n",
    "minority_class = train_class_counts.idxmin()\n",
    "\n",
    "# Create balanced training set using simple random oversampling\n",
    "# Get majority and minority class samples\n",
    "X_majority = X_train_ml[y_train_ml == majority_class]\n",
    "X_minority = X_train_ml[y_train_ml == minority_class]\n",
    "\n",
    "# Oversample minority class with replacement\n",
    "X_minority_oversampled = X_minority.sample(len(X_majority), replace=True, random_state=42)\n",
    "y_minority_oversampled = pd.Series([minority_class] * len(X_minority_oversampled))\n",
    "\n",
    "# Combine majority and oversampled minority\n",
    "X_train_ml_balanced = pd.concat([X_majority, X_minority_oversampled])\n",
    "y_train_ml_balanced = pd.concat([\n",
    "    pd.Series([majority_class] * len(X_majority)),\n",
    "    y_minority_oversampled\n",
    "])\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.RandomState(42).permutation(len(X_train_ml_balanced))\n",
    "X_train_ml_balanced = X_train_ml_balanced.iloc[shuffle_idx].reset_index(drop=True)\n",
    "y_train_ml_balanced = y_train_ml_balanced.iloc[shuffle_idx].reset_index(drop=True)\n",
    "\n",
    "# Create final ML dataframes\n",
    "df_train_ml = pd.DataFrame(X_train_ml_balanced)\n",
    "df_train_ml['Email Type'] = y_train_ml_balanced\n",
    "df_test_ml = pd.DataFrame(X_test_ml)\n",
    "df_test_ml['Email Type'] = y_test_ml\n",
    "\n",
    "print(\"\\nTraditional ML datasets created:\")\n",
    "print(f\"Training set: {len(df_train_ml)} samples\")\n",
    "print(f\"Test set: {len(df_test_ml)} samples\")\n",
    "print(\"Class distribution in training set:\")\n",
    "print(df_train_ml['Email Type'].value_counts())\n",
    "\n",
    "# Save traditional ML datasets\n",
    "df_train_ml.to_csv(os.path.join(balanced_dir, 'train_ml.csv'), index=False)\n",
    "df_train_ml.to_csv(os.path.join(balanced_dir, 'val_ml.csv'), index=False)\n",
    "print(\"\\nAll ML datasets saved to CSV files in balanced_data_files directory\")"
   ],
   "id": "5b9b6b27d7c230ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traditional ML datasets created:\n",
      "Training set: 18116 samples\n",
      "Test set: 3730 samples\n",
      "Class distribution in training set:\n",
      "Email Type\n",
      "Safe Email        9058\n",
      "Phishing Email    9058\n",
      "Name: count, dtype: int64\n",
      "\n",
      "All ML datasets saved to CSV files in balanced_data_files directory\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
